# Vision Transformers (ViT):
Traditionally, Convolutional Neural Networks (CNNs) have been the go-to models for visual tasks, but ViTs offer a novel alternative. By leveraging the self-attention mechanisms and Transformer architectures, ViTs break the limitations imposed by local receptive fields in CNNs.
## Why ViT?
They capture global dependencies and long-range interactions within an image. This leads to remarkable performance improvements in various computer vision tasks, including image classification, object detection, and image generation.

The networkâ€™s ability to focus on different input areas at different times allows it to capture local and global relationships, so collect spatial relationships in images more effectively than other types of neural networks. They have the ability to effectively model high-dimensional visual data.
transformers are a type of neural network architecture that:

processes incoming data through self-attention techniques. 
The self-attention mechanism
allows the network to focus on different sections of the input data at other times. It allows to capture both local and global associations
![Transformer](transformer_architecture.jpg)

![Transformer Image](https://ibb.co/J2DdNQp)

###References:
_*
