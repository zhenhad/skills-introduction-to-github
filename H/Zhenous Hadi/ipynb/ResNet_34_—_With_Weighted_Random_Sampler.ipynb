{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Breast Cancer Classification using Transfer Learning in PyTorch (ResNet34-Resampling)\n",
        "\n",
        "2 Classes:\n",
        "* 0: No cancer (benign)\n",
        "* 1: Cancer (malignant)"
      ],
      "metadata": {
        "id": "WPGH3wcPGC3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import time\n",
        "from torchviz import make_dot\n",
        "import hiddenlayer as hl\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
        "\n",
        "project_name='Breast-Cancer-Classification-Resampling-ResNet34-No-Augmentation'"
      ],
      "metadata": {
        "id": "bie8ybWdGIvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Load the Data & Prepare the Data For Training\n"
      ],
      "metadata": {
        "id": "C9jHEp5UGMMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Transform\n",
        "train_tfms = tt.Compose([tt.ToTensor()])\n",
        "valid_tfms = tt.Compose([tt.ToTensor()])"
      ],
      "metadata": {
        "id": "RehicuvTGM0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train, validation and test dataset\n",
        "data_dir = os.getcwd()\n",
        "train_file = os.path.join(data_dir, \"train\")\n",
        "val_file = os.path.join(data_dir, \"validation\")\n",
        "test_file = os.path.join(data_dir, \"test\")\n",
        "\n",
        "train_ds = ImageFolder(train_file, train_tfms)\n",
        "val_ds = ImageFolder(val_file, valid_tfms)\n",
        "test_ds = ImageFolder(test_file, valid_tfms)"
      ],
      "metadata": {
        "id": "jetkxFPxGR0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Size\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "dtje_6hhGT7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######## Before Resampling\n",
        "\n",
        "# PyTorch data loaders\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers=3, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds, batch_size*2, num_workers=3, pin_memory=True)\n",
        "\n",
        "train_records = Counter(train_dl.dataset.targets)\n",
        "# val_records = Counter(val_dl.dataset.targets)\n",
        "# test_records = Counter(test_dl.dataset.targets)\n",
        "\n",
        "print(train_records)\n",
        "# Plot Train Records\n",
        "plt.bar(train_records.keys(), train_records.values(), tick_label=list(train_records.keys()))\n",
        "plt.title(\"Number of Training Images for Each Class (Before Resampling)\")\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.savefig(\"before_resampling\")"
      ],
      "metadata": {
        "id": "XrKxSTRaGVX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######## After Resampling\n",
        "targets = train_dl.dataset.targets\n",
        "class_count = np.unique(targets, return_counts=True)[1]\n",
        "\n",
        "weight = 1. / class_count\n",
        "samples_weight = weight[targets]\n",
        "samples_weight = torch.from_numpy(samples_weight)\n",
        "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, sampler=sampler)\n",
        "\n",
        "i=0\n",
        "for _, (data, target) in enumerate(train_dl):\n",
        "    if i==0:\n",
        "        temp = Counter(target.numpy())\n",
        "        i += 1\n",
        "    else:\n",
        "        temp += Counter(target.numpy())\n",
        "\n",
        "print(temp)\n",
        "# Plot Train Records\n",
        "plt.bar(temp.keys(), temp.values(), tick_label=list(temp.keys()))\n",
        "plt.title(\"Number of Training Images for Each Class (After Resampling)\")\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.savefig(\"after_resampling\")"
      ],
      "metadata": {
        "id": "OSyhgmYhGYOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See sample Images\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 12))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n",
        "        break\n",
        "\n",
        "show_batch(train_dl)"
      ],
      "metadata": {
        "id": "zmVzLFf9GZE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: ResNet34 Model\n"
      ],
      "metadata": {
        "id": "R5oeZJZSGdDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def F_score(output, label, threshold=0.5, beta=1):\n",
        "    prob = output > threshold\n",
        "    label = label > threshold\n",
        "\n",
        "    TP = (prob & label).sum(1).float()\n",
        "    TN = ((~prob) & (~label)).sum(1).float()\n",
        "    FP = (prob & (~label)).sum(1).float()\n",
        "    FN = ((~prob) & label).sum(1).float()\n",
        "\n",
        "    precision = torch.mean(TP / (TP + FP + 1e-12))\n",
        "    recall = torch.mean(TP / (TP + FN + 1e-12))\n",
        "    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n",
        "    return F2.mean(0)"
      ],
      "metadata": {
        "id": "MVVtXZDyGbSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, targets = batch\n",
        "        targets = torch.reshape(targets.type(torch.cuda.FloatTensor), (len(targets), 1))\n",
        "        out = self(images)\n",
        "        loss = F.binary_cross_entropy(out, targets)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, targets = batch\n",
        "        targets = torch.reshape(targets.type(torch.cuda.FloatTensor), (len(targets), 1))\n",
        "        out = self(images)                           # Generate predictions\n",
        "        loss = F.binary_cross_entropy(out, targets)  # Calculate loss\n",
        "        score = F_score(out, targets)\n",
        "        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_scores = [x['val_score'] for x in outputs]\n",
        "        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_score']))"
      ],
      "metadata": {
        "id": "ArbF3balGlif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BreastCancerResnet34(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet34(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, 1)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "    def freeze(self):\n",
        "        # To freeze the residual layers\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = False\n",
        "        for param in self.network.fc.parameters():\n",
        "            param.require_grad = True\n",
        "\n",
        "    def unfreeze(self):\n",
        "        # Unfreeze all layers\n",
        "        for param in self.network.parameters():\n",
        "            param.require_grad = True"
      ],
      "metadata": {
        "id": "1iQSxEpmGnqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "9YSc6VPWGpdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "test_dl = DeviceDataLoader(test_dl, device)"
      ],
      "metadata": {
        "id": "SIM202XzGrgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Train the Model\n"
      ],
      "metadata": {
        "id": "zctkMoZDGv3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "ekFKSZ4SGs4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = to_device(BreastCancerResnet34(), device)\n"
      ],
      "metadata": {
        "id": "zZ1fO5j4Gzv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = [evaluate(model, val_dl)]\n",
        "history"
      ],
      "metadata": {
        "id": "vXlhMTPBG0bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.freeze()"
      ],
      "metadata": {
        "id": "rYDew7eKG2IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ],
      "metadata": {
        "id": "RpcMMDS_G5IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n",
        "                         grad_clip=grad_clip,\n",
        "                         weight_decay=weight_decay,\n",
        "                         opt_func=opt_func)\n",
        "\n",
        "train_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "1EIUQxe8G7-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.unfreeze()\n"
      ],
      "metadata": {
        "id": "sxP53wQlG-o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "history += fit_one_cycle(epochs, 0.001, model, train_dl, val_dl,\n",
        "                         grad_clip=grad_clip,\n",
        "                         weight_decay=weight_decay,\n",
        "                         opt_func=opt_func)\n",
        "train_time += time.time() - start_time"
      ],
      "metadata": {
        "id": "agdCYU98HA3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_scores(history):\n",
        "    scores = [x['val_score'] for x in history]\n",
        "    plt.plot(scores, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('score')\n",
        "    plt.title('F1 score vs. No. of epochs')\n",
        "    plt.show()\n",
        "    plt.savefig(\"ResNet34_resampling_scores_no_augmentation\")"
      ],
      "metadata": {
        "id": "AOFpKIxnHEtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs')\n",
        "    plt.show()\n",
        "    plt.savefig(\"ResNet34_resampling_losses_no_augmentation\")"
      ],
      "metadata": {
        "id": "T4U7MTc7HHDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lrs(history):\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel('Batch no.')\n",
        "    plt.ylabel('Learning rate')\n",
        "    plt.title('Learning Rate vs. Batch no.')\n",
        "    plt.show()\n",
        "    plt.savefig(\"ResNet34_resampling_lrs_no_augmentation\")"
      ],
      "metadata": {
        "id": "Sut5KhotHI9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_scores(history)\n",
        "plot_losses(history)\n",
        "plot_lrs(history)"
      ],
      "metadata": {
        "id": "_70EYJWQHKw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Generate Predictions and Save Model\n"
      ],
      "metadata": {
        "id": "SkIaHY6CHOoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sample(img, invert=True):\n",
        "    if invert:\n",
        "        plt.imshow(1 - img.permute((1, 2, 0)))\n",
        "    else:\n",
        "        plt.imshow(img.permute(1, 2, 0))\n",
        "\n",
        "def predict_single(image, label, threshold=0.5):\n",
        "    xb = image.unsqueeze(0)\n",
        "    xb = to_device(xb, device)\n",
        "    preds = model(xb)\n",
        "    prediction = preds[0]\n",
        "    pred_label = [1 if prediction>threshold else 0][0]\n",
        "    print(\"Predicted Prob: \", prediction[0])\n",
        "    print(\"Predicted Label: \", pred_label)\n",
        "    print(\"Actual Label: \", label)\n",
        "    show_sample(image)"
      ],
      "metadata": {
        "id": "fUOgkLmYHMaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_single(*test_ds[100])\n"
      ],
      "metadata": {
        "id": "-pZktauFHRvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_single(*test_ds[4990])\n"
      ],
      "metadata": {
        "id": "r-g3pYViHUSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Generate Prediction\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_dl(dl, model, threshold=0.5):\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_probs = []\n",
        "    for xb, _ in tqdm(dl):\n",
        "        probs = model(xb)\n",
        "        batch_probs.append(probs.cpu().detach())\n",
        "    batch_probs = torch.cat(batch_probs)\n",
        "    return [int(x) for x in batch_probs>threshold]"
      ],
      "metadata": {
        "id": "fPUxOZZUHWIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze Prediction Results\n",
        "test_preds = predict_dl(test_dl, model)\n",
        "actual_label = test_dl.dl.dataset.targets"
      ],
      "metadata": {
        "id": "WjgRr_PVHXKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(actual_label, test_preds)\n",
        "f_score = float(np.array(F_score(torch.tensor(np.array(test_preds).reshape(len(test_preds), 1)), torch.tensor(np.array(actual_label).reshape(len(actual_label), 1)))))\n",
        "accuracy = accuracy_score(actual_label, test_preds)\n",
        "cm = confusion_matrix(actual_label, test_preds)\n",
        "report = classification_report(actual_label, test_preds)\n",
        "\n",
        "print(\"Model F-Score (Test Data): \", f_score)\n",
        "print(\"Model F1-Score (Test Data): \", f1)\n",
        "print(\"Model Accuracy: \", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in \"01\"], columns = [i for i in \"01\"])\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(df_cm, cmap=\"Oranges\", annot=True, annot_kws={\"size\": 16})\n",
        "plt.title(\"Plot of Confusion Matrix\")\n",
        "plt.show()\n",
        "plt.savefig(\"ResNet34_resampling_CM\")"
      ],
      "metadata": {
        "id": "cpKHSddoHZGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_fname = 'breast-cancer-classification-ResNet34-resampling-no-aug.pth'\n",
        "torch.save(model.state_dict(), weights_fname)"
      ],
      "metadata": {
        "id": "HsBKs860HcvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "batch_probs = []\n",
        "for xb, _ in tqdm(test_dl):\n",
        "    xb = xb[1:2,:,:,:]\n",
        "    probs = model(xb)\n",
        "    graph = hl.build_graph(model, xb)\n",
        "    graph.theme = hl.graph.THEMES['blue'].copy()\n",
        "    graph.save('ResNet34_resampling_no_aug', format='png')\n",
        "    make_dot(probs, params=dict(list(model.named_parameters()))).render(\"ResNet34__resampling_no_aug_torchviz\", format=\"png\")\n",
        "    break"
      ],
      "metadata": {
        "id": "J7yDfX-GHeyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jovian\n",
        "\n",
        "jovian.reset()\n",
        "jovian.log_hyperparams(arch='resnet34',\n",
        "                       epochs=2*epochs,\n",
        "                       lr=max_lr,\n",
        "                       scheduler='one-cycle',\n",
        "                       weight_decay=weight_decay,\n",
        "                       grad_clip=grad_clip,\n",
        "                       opt=opt_func.__name__)"
      ],
      "metadata": {
        "id": "cE9vqdz-HglB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jovian.log_metrics(val_loss=history[-1]['val_loss'],\n",
        "                   val_score=history[-1]['val_score'],\n",
        "                   train_loss=history[-1]['train_loss'],\n",
        "                   time=train_time)"
      ],
      "metadata": {
        "id": "_44-tBVMHh7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jovian.commit(filename=\"ResNet34-Breast Cancer Classification-Resampling-Final-Without-Augmentation\", project=project_name, environment=None, outputs=[weights_fname])"
      ],
      "metadata": {
        "id": "77oW73lCHihA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}